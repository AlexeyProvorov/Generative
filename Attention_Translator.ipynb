{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxDk6/XkrF3Yx4SHN2j7NZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexeyProvorov/Generative/blob/master/Attention_Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# === Подготовка данных ===\n",
        "\n",
        "# Наборы предложений на английском и французском языках\n",
        "english_sentences = [\n",
        "    \"hello how are you\",\n",
        "    \"i am fine thank you\",\n",
        "    \"what is your name\",\n",
        "    \"my name is chatgpt\",\n",
        "    \"nice to meet you\"\n",
        "]\n",
        "\n",
        "french_sentences = [\n",
        "    \"bonjour comment ça va\",\n",
        "    \"je vais bien merci\",\n",
        "    \"quel est votre nom\",\n",
        "    \"mon nom est chatgpt\",\n",
        "    \"ravi de vous rencontrer\"\n",
        "]\n",
        "\n",
        "# Функция для создания словаря из списка предложений\n",
        "def build_vocab(sentences):\n",
        "    \"\"\"\n",
        "    Создает словарь для языка, сопоставляя каждое слово с уникальным индексом.\n",
        "    Начальные токены:\n",
        "    - <PAD>: заполнение для выравнивания последовательностей\n",
        "    - <SOS>: начало последовательности\n",
        "    - <EOS>: конец последовательности\n",
        "    - <UNK>: неизвестное слово\n",
        "    \"\"\"\n",
        "    vocab = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "    index = 4  # Начальный индекс для новых слов\n",
        "    for sentence in sentences:\n",
        "        for word in sentence.split():\n",
        "            if word not in vocab:\n",
        "                vocab[word] = index\n",
        "                index += 1\n",
        "    return vocab\n",
        "\n",
        "# Создаем словари для английского и французского языков\n",
        "english_vocab = build_vocab(english_sentences)\n",
        "french_vocab = build_vocab(french_sentences)\n",
        "\n",
        "# Функция для преобразования предложения в последовательность индексов\n",
        "def sentence_to_indices(sentence, vocab):\n",
        "    \"\"\"\n",
        "    Преобразует предложение в список индексов на основе словаря.\n",
        "    Добавляет токен <EOS> в конце последовательности.\n",
        "    \"\"\"\n",
        "    indices = [vocab.get(word, vocab[\"<UNK>\"]) for word in sentence.split()]\n",
        "    indices.append(vocab[\"<EOS>\"])  # Добавляем токен конца последовательности\n",
        "    return indices\n",
        "\n",
        "# Преобразуем все предложения в последовательности индексов\n",
        "english_sequences = [sentence_to_indices(s, english_vocab) for s in english_sentences]\n",
        "french_sequences = [sentence_to_indices(s, french_vocab) for s in french_sentences]\n",
        "\n",
        "# === Параметры модели ===\n",
        "\n",
        "INPUT_DIM = len(english_vocab)   # Размер словаря входного языка\n",
        "OUTPUT_DIM = len(french_vocab)   # Размер словаря выходного языка\n",
        "ENC_EMB_DIM = 256                # Размерность эмбеддингов в кодере\n",
        "DEC_EMB_DIM = 256                # Размерность эмбеддингов в декодере\n",
        "HID_DIM = 512                    # Размерность скрытых состояний в RNN\n",
        "\n",
        "# === Создание датасета и загрузчика данных ===\n",
        "\n",
        "# Определяем класс датасета для загрузки данных\n",
        "class TranslationDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета для машинного перевода.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_sequences, target_sequences):\n",
        "        self.input_sequences = input_sequences  # Последовательности на входном языке\n",
        "        self.target_sequences = target_sequences  # Последовательности на целевом языке\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_sequences[idx], self.target_sequences[idx]\n",
        "\n",
        "# Создаем экземпляр датасета\n",
        "dataset = TranslationDataset(english_sequences, french_sequences)\n",
        "\n",
        "# Создаем загрузчик данных для итерации по датасету\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# === Реализация модели с механизмом внимания ===\n",
        "\n",
        "# --- Кодер (Encoder) ---\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
        "        super().__init__()\n",
        "        # Слой эмбеддингов\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        # RNN (GRU) для обработки последовательности\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        \"\"\"\n",
        "        Проводит входную последовательность через кодер.\n",
        "        src: [batch_size, src_len] - входные последовательности\n",
        "        \"\"\"\n",
        "        # Преобразуем входные индексы в эмбеддинги\n",
        "        embedded = self.embedding(src)  # [batch_size, src_len, emb_dim]\n",
        "        # Пропускаем через RNN\n",
        "        outputs, hidden = self.rnn(embedded)  # outputs: все скрытые состояния, hidden: последнее скрытое состояние\n",
        "        return outputs, hidden  # outputs: [batch_size, src_len, hid_dim], hidden: [1, batch_size, hid_dim]\n",
        "\n",
        "# --- Механизм внимания (Attention) ---\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        # Линейный слой для вычисления энергии\n",
        "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        # Вектор контекста\n",
        "        self.v = nn.Parameter(torch.rand(hid_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        Вычисляет веса внимания.\n",
        "        hidden: [batch_size, hid_dim] - текущее скрытое состояние декодера\n",
        "        encoder_outputs: [batch_size, src_len, hid_dim] - скрытые состояния кодера\n",
        "        \"\"\"\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        # Повторяем скрытое состояние декодера для каждого временного шага входной последовательности\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # [batch_size, src_len, hid_dim]\n",
        "\n",
        "        # Конкатенируем скрытые состояния кодера и декодера и вычисляем энергию\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch_size, src_len, hid_dim]\n",
        "\n",
        "        # Транспонируем для умножения с v\n",
        "        energy = energy.permute(0, 2, 1)  # [batch_size, hid_dim, src_len]\n",
        "\n",
        "        # Повторяем v для каждого примера в батче\n",
        "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [batch_size, 1, hid_dim]\n",
        "\n",
        "        # Вычисляем скалярное произведение между v и энергией\n",
        "        attention = torch.bmm(v, energy).squeeze(1)  # [batch_size, src_len]\n",
        "\n",
        "        # Применяем softmax для получения вероятностей\n",
        "        return torch.softmax(attention, dim=1)  # [batch_size, src_len]\n",
        "\n",
        "# --- Декодер (Decoder) ---\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim      # Размер словаря выходного языка\n",
        "        self.attention = attention        # Механизм внимания\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)  # Слой эмбеддингов\n",
        "        self.rnn = nn.GRU(hid_dim + emb_dim, hid_dim, batch_first=True)  # RNN с учетом контекста внимания\n",
        "        self.fc_out = nn.Linear(hid_dim * 2 + emb_dim, output_dim)  # Выходной линейный слой\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        Выполняет один шаг декодирования.\n",
        "        input: [batch_size] - текущий токен на входе декодера\n",
        "        hidden: [batch_size, hid_dim] - предыдущее скрытое состояние декодера\n",
        "        encoder_outputs: [batch_size, src_len, hid_dim] - скрытые состояния кодера\n",
        "        \"\"\"\n",
        "        # Добавляем дополнительную размерность для времени\n",
        "        input = input.unsqueeze(1)  # [batch_size, 1]\n",
        "\n",
        "        # Преобразуем входные индексы в эмбеддинги\n",
        "        embedded = self.embedding(input)  # [batch_size, 1, emb_dim]\n",
        "\n",
        "        # Вычисляем веса внимания\n",
        "        a = self.attention(hidden, encoder_outputs)  # [batch_size, src_len]\n",
        "\n",
        "        # Добавляем размерность для матричного умножения\n",
        "        a = a.unsqueeze(1)  # [batch_size, 1, src_len]\n",
        "\n",
        "        # Вычисляем контекстный вектор как взвешенную сумму скрытых состояний кодера\n",
        "        weighted = torch.bmm(a, encoder_outputs)  # [batch_size, 1, hid_dim]\n",
        "\n",
        "        # Объединяем эмбеддинги и контекстный вектор для подачи в RNN\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)  # [batch_size, 1, emb_dim + hid_dim]\n",
        "\n",
        "        # Пропускаем через RNN\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))  # output: [batch_size, 1, hid_dim]\n",
        "\n",
        "        # Удаляем размерность времени\n",
        "        output = output.squeeze(1)    # [batch_size, hid_dim]\n",
        "        embedded = embedded.squeeze(1)  # [batch_size, emb_dim]\n",
        "        weighted = weighted.squeeze(1)  # [batch_size, hid_dim]\n",
        "\n",
        "        # Прогнозируем следующий токен\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))  # [batch_size, output_dim]\n",
        "\n",
        "        # Возвращаем прогноз, новое скрытое состояние и веса внимания\n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)\n",
        "\n",
        "# --- Модель Seq2Seq ---\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder  # Кодер\n",
        "        self.decoder = decoder  # Декодер\n",
        "        self.device = device    # Устройство (CPU или GPU)\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        \"\"\"\n",
        "        Проводит входную последовательность через модель и генерирует выходную последовательность.\n",
        "        src: [batch_size, src_len] - входные последовательности\n",
        "        trg: [batch_size, trg_len] - целевые последовательности\n",
        "        teacher_forcing_ratio: вероятность использования правильного следующего слова в качестве входа\n",
        "        \"\"\"\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # Подготовим тензор для хранения выходов\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # Пропускаем входную последовательность через кодер\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # Начинаем с токена <SOS> в декодере\n",
        "        input = trg[:, 0]  # Первый токен в целевой последовательности\n",
        "\n",
        "        attentions = []  # Список для хранения весов внимания на каждом шаге\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # Выполняем один шаг декодирования\n",
        "            output, hidden, attention = self.decoder(input, hidden, encoder_outputs)\n",
        "\n",
        "            # Сохраняем прогноз\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            # Решаем, использовать ли teacher forcing\n",
        "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)  # Индекс слова с наибольшей вероятностью\n",
        "\n",
        "            # Следующий вход для декодера\n",
        "            input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "            # Сохраняем веса внимания\n",
        "            attentions.append(attention.cpu().detach().numpy())\n",
        "\n",
        "        # Возвращаем все выходы и веса внимания\n",
        "        return outputs, attentions\n",
        "\n",
        "# === Инициализация модели и параметров ===\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Создаем экземпляры кодера, механизма внимания и декодера\n",
        "attn = Attention(HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, attn)\n",
        "\n",
        "# Создаем модель Seq2Seq\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "# Определяем функцию потерь и оптимизатор\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=english_vocab[\"<PAD>\"])  # Игнорируем потери от паддингов\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# === Обучение модели ===\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, clip):\n",
        "    \"\"\"\n",
        "    Обучает модель на одном проходе по датасету.\n",
        "    \"\"\"\n",
        "    model.train()  # Переводим модель в режим обучения\n",
        "    epoch_loss = 0  # Суммарный убыток за эпоху\n",
        "\n",
        "    for src, trg in dataloader:\n",
        "        # Преобразуем данные в тензоры и перемещаем на устройство\n",
        "        src = torch.LongTensor(src).to(device)\n",
        "        trg = torch.LongTensor(trg).to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Обнуляем градиенты\n",
        "\n",
        "        # Получаем прогнозы от модели\n",
        "        output, _ = model(src, trg)\n",
        "\n",
        "        # Преобразуем выходы и целевые последовательности для функции потерь\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)  # Убираем токен <SOS>\n",
        "        trg = trg[:, 1:].reshape(-1)  # Убираем токен <SOS>\n",
        "\n",
        "        # Вычисляем убыток\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        # Обратное распространение ошибки\n",
        "        loss.backward()\n",
        "\n",
        "        # Ограничиваем градиенты для предотвращения взрыва градиентов\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # Обновляем параметры модели\n",
        "        optimizer.step()\n",
        "\n",
        "        # Накопление убытка\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Возвращаем средний убыток за эпоху\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "# === Функция для перевода предложения ===\n",
        "\n",
        "def translate_sentence(model, sentence, english_vocab, french_vocab, max_len=10):\n",
        "    \"\"\"\n",
        "    Переводит входное предложение с использованием обученной модели.\n",
        "    \"\"\"\n",
        "    model.eval()  # Переводим модель в режим оценки\n",
        "\n",
        "    # Преобразуем предложение в последовательность индексов\n",
        "    tokens = sentence.split()\n",
        "    indices = [english_vocab.get(token, english_vocab[\"<UNK>\"]) for token in tokens]\n",
        "    src_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)  # Добавляем размерность батча\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Получаем скрытые состояния кодера\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indices = [french_vocab[\"<SOS>\"]]  # Начинаем с токена <SOS>\n",
        "    attentions = []  # Список для хранения весов внимания\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indices[-1]]).to(device)  # Текущий вход декодера\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Выполняем один шаг декодирования\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
        "\n",
        "        # Получаем индекс слова с наибольшей вероятностью\n",
        "        pred_token = output.argmax(1).item()\n",
        "\n",
        "        # Добавляем предсказанный токен в последовательность\n",
        "        trg_indices.append(pred_token)\n",
        "\n",
        "        # Сохраняем веса внимания\n",
        "        attentions.append(attention.cpu().numpy())\n",
        "\n",
        "        # Останавливаем перевод, если встретили токен <EOS>\n",
        "        if pred_token == french_vocab[\"<EOS>\"]:\n",
        "            break\n",
        "\n",
        "    # Преобразуем индексы в слова\n",
        "    trg_tokens = [list(french_vocab.keys())[list(french_vocab.values()).index(idx)] for idx in trg_indices[1:]]\n",
        "\n",
        "    # Возвращаем переведенное предложение и веса внимания\n",
        "    return ' '.join(trg_tokens), attentions\n",
        "\n",
        "# === Запуск обучения модели ===\n",
        "\n",
        "N_EPOCHS = 1000  # Количество эпох\n",
        "CLIP = 1         # Ограничение градиентов\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    loss = train(model, dataloader, optimizer, criterion, CLIP)\n",
        "\n",
        "    # Выводим информацию каждые 100 эпох\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch: {epoch + 1}, Loss: {loss:.4f}')\n",
        "\n",
        "# === Пример перевода ===\n",
        "\n",
        "sentence = \"hello how are you\"\n",
        "translation, attentions = translate_sentence(model, sentence, english_vocab, french_vocab)\n",
        "print(f\"Input Sentence: {sentence}\")\n",
        "print(f\"Translated Sentence: {translation}\")\n"
      ],
      "metadata": {
        "id": "fi-VCRfov_om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def display_attention(sentence, translation, attentions):\n",
        "    \"\"\"\n",
        "    Визуализирует веса внимания между входным и выходным предложениями.\n",
        "    \"\"\"\n",
        "    # Преобразуем веса внимания в numpy массив\n",
        "    attention = np.array(attentions)\n",
        "\n",
        "    # Создаём фигуру для визуализации\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    # Используем heatmap для отображения весов внимания\n",
        "    sns.heatmap(attention[:len(translation.split()), :len(sentence.split())],\n",
        "                xticklabels=sentence.split(),\n",
        "                yticklabels=translation.split(),\n",
        "                cmap='viridis', ax=ax)\n",
        "\n",
        "    plt.xlabel('Input Sentence')\n",
        "    plt.ylabel('Translated Sentence')\n",
        "    plt.show()\n",
        "\n",
        "# Вызов функции для визуализации\n",
        "display_attention(sentence, translation, attentions)\n"
      ],
      "metadata": {
        "id": "fY309phTv_lG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}